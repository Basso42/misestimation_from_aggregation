{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misestimation from Aggregation: Tutorial and Experiments\n",
    "\n",
    "This notebook demonstrates the use of the `misestimation_from_aggregation` Python package, which implements the methodology from \"Estimating the loss of economic predictability from aggregating firm-level production networks\" by Diem et al. (2023).\n",
    "\n",
    "## Overview\n",
    "\n",
    "The package provides tools for:\n",
    "1. **Network Aggregation**: Converting firm-level networks to sector-level representations\n",
    "2. **Similarity Analysis**: Calculating input/output vector overlaps between firms\n",
    "3. **Shock Simulation**: Generating synthetic firm-level shocks that maintain sector-level consistency\n",
    "4. **Economic Impact Assessment**: Comparing firm-level vs sector-level predictive accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from scipy.sparse import csr_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import our package\n",
    "from misestimation_from_aggregation import (\n",
    "    NetworkAggregator, \n",
    "    SimilarityCalculator, \n",
    "    ShockSampler\n",
    ")\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Example Network from Figure 1\n",
    "\n",
    "Let's start by recreating the minimal example from Figure 1 of the paper. This network has 11 firms distributed across 5 sectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network parameters from Figure 1\n",
    "n_firms = 11\n",
    "sector_affiliations = np.array([1, 1, 2, 2, 2, 3, 3, 4, 4, 5, 5])\n",
    "\n",
    "# Network edges: (supplier, buyer, weight)\n",
    "edges = [\n",
    "    (3, 6, 1), (4, 6, 1), (4, 7, 1), (5, 7, 1),\n",
    "    (6, 1, 1), (6, 2, 1), (7, 10, 1), (7, 11, 1),\n",
    "    (8, 1, 1), (8, 2, 1), (9, 11, 1)\n",
    "]\n",
    "\n",
    "# Create adjacency matrix (firm-level network W)\n",
    "W = np.zeros((n_firms, n_firms))\n",
    "for supplier, buyer, weight in edges:\n",
    "    W[supplier-1, buyer-1] = weight  # Convert to 0-indexed\n",
    "\n",
    "print(f\"Firm-level network W: {W.shape}\")\n",
    "print(f\"Number of edges: {np.sum(W > 0)}\")\n",
    "print(f\"Total flow: {np.sum(W)}\")\n",
    "print(f\"Sectors: {np.unique(sector_affiliations)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_network(adjacency_matrix, sectors, title, ax):\n",
    "    \"\"\"Plot network with sector-based coloring.\"\"\"\n",
    "    G = nx.from_numpy_array(adjacency_matrix, create_using=nx.DiGraph)\n",
    "    \n",
    "    # Create color map for sectors\n",
    "    unique_sectors = np.unique(sectors)\n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, len(unique_sectors)))\n",
    "    sector_colors = {sector: colors[i] for i, sector in enumerate(unique_sectors)}\n",
    "    node_colors = [sector_colors[sectors[i]] for i in range(len(sectors))]\n",
    "    \n",
    "    # Layout\n",
    "    pos = nx.spring_layout(G, seed=42)\n",
    "    \n",
    "    # Draw network\n",
    "    nx.draw(G, pos, ax=ax, \n",
    "            node_color=node_colors,\n",
    "            node_size=500,\n",
    "            arrows=True,\n",
    "            arrowsize=20,\n",
    "            edge_color='gray',\n",
    "            alpha=0.8)\n",
    "    \n",
    "    # Add labels\n",
    "    labels = {i: f'{i+1}\\n(S{sectors[i]})' for i in range(len(sectors))}\n",
    "    nx.draw_networkx_labels(G, pos, labels, ax=ax, font_size=8)\n",
    "    \n",
    "    ax.set_title(title)\n",
    "    return ax\n",
    "\n",
    "# Plot firm-level and sector-level networks\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Firm-level network\n",
    "plot_network(W, sector_affiliations, \"Firm-level Network (W)\", ax1)\n",
    "\n",
    "# Aggregate to sector level\n",
    "aggregator = NetworkAggregator()\n",
    "Z = aggregator.aggregate_to_sectors(W, sector_affiliations)\n",
    "unique_sectors = np.unique(sector_affiliations)\n",
    "\n",
    "plot_network(Z, unique_sectors, \"Sector-level Network (Z)\", ax2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Sector-level network Z: {Z.shape}\")\n",
    "print(f\"Total flow preserved: {np.sum(Z)} = {np.sum(W)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Input-Output Vector Analysis\n",
    "\n",
    "Next, we calculate the overlap coefficients (IOC and OOC) that measure similarity between firms' input and output vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate input and output aggregations\n",
    "supplier_agg = aggregator.aggregate_suppliers(W, sector_affiliations)\n",
    "buyer_agg = aggregator.aggregate_buyers(W, sector_affiliations)\n",
    "\n",
    "print(\"Input aggregation (suppliers → sectors):\")\n",
    "print(f\"Volume matrix shape: {supplier_agg['volume'].shape}\")\n",
    "print(\"Sample input vectors (sectors × firms):\")\n",
    "print(supplier_agg['volume'][:, :5])  # First 5 firms\n",
    "\n",
    "print(\"\\nOutput aggregation (buyers → sectors):\")\n",
    "print(f\"Volume matrix shape: {buyer_agg['volume'].shape}\")\n",
    "print(\"Sample output vectors (sectors × firms):\")\n",
    "print(buyer_agg['volume'][:, :5])  # First 5 firms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Similarity Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize similarity calculator\n",
    "similarity_calc = SimilarityCalculator()\n",
    "\n",
    "# Calculate input vector similarities (IOC)\n",
    "input_similarities = similarity_calc.calculate_io_similarities(\n",
    "    W, sector_affiliations, \n",
    "    direction=\"input\", \n",
    "    measure=\"overlap_relative\"\n",
    ")\n",
    "\n",
    "# Calculate output vector similarities (OOC)\n",
    "output_similarities = similarity_calc.calculate_io_similarities(\n",
    "    W, sector_affiliations, \n",
    "    direction=\"output\", \n",
    "    measure=\"overlap_relative\"\n",
    ")\n",
    "\n",
    "print(\"Input vector overlaps by sector:\")\n",
    "for sector, sim_matrix in input_similarities.items():\n",
    "    if sim_matrix.size > 0:\n",
    "        print(f\"{sector}: {sim_matrix.shape}\")\n",
    "        if sim_matrix.size > 1:\n",
    "            print(f\"  Sample similarities: {sim_matrix.flatten()[:5]}\")\n",
    "\n",
    "print(\"\\nOutput vector overlaps by sector:\")\n",
    "for sector, sim_matrix in output_similarities.items():\n",
    "    if sim_matrix.size > 0:\n",
    "        print(f\"{sector}: {sim_matrix.shape}\")\n",
    "        if sim_matrix.size > 1:\n",
    "            print(f\"  Sample similarities: {sim_matrix.flatten()[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine Specific Results from the Paper\n",
    "\n",
    "The paper mentions specific examples:\n",
    "- Sector 3 firms have input overlap of 1 (both buy from sector 2)\n",
    "- Sector 5 firms have input overlap of 0.5 (firm 10 buys only from sector 3, firm 11 buys from sectors 3 and 4)\n",
    "- Sector 3 firms have output overlap of 0 (firm 6 sells only to sector 1, firm 7 only to sector 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine specific cases mentioned in the paper\n",
    "print(\"Detailed analysis of specific sectors:\")\n",
    "\n",
    "# Sector 3 analysis (firms 6 and 7, i.e., indices 5 and 6)\n",
    "sector_3_firms = np.where(sector_affiliations == 3)[0]\n",
    "print(f\"\\nSector 3 firms: {sector_3_firms + 1} (0-indexed: {sector_3_firms})\")\n",
    "\n",
    "# Input vectors for sector 3 firms\n",
    "print(\"Input vectors (what they buy from each sector):\")\n",
    "for i, firm_idx in enumerate(sector_3_firms):\n",
    "    firm_inputs = supplier_agg['volume'][:, firm_idx]\n",
    "    print(f\"  Firm {firm_idx + 1}: {firm_inputs}\")\n",
    "\n",
    "# Output vectors for sector 3 firms  \n",
    "print(\"Output vectors (what they sell to each sector):\")\n",
    "for i, firm_idx in enumerate(sector_3_firms):\n",
    "    firm_outputs = buyer_agg['volume'][:, firm_idx]\n",
    "    print(f\"  Firm {firm_idx + 1}: {firm_outputs}\")\n",
    "\n",
    "# Sector 5 analysis (firms 10 and 11, i.e., indices 9 and 10)\n",
    "sector_5_firms = np.where(sector_affiliations == 5)[0]\n",
    "print(f\"\\nSector 5 firms: {sector_5_firms + 1} (0-indexed: {sector_5_firms})\")\n",
    "\n",
    "print(\"Input vectors (what they buy from each sector):\")\n",
    "for i, firm_idx in enumerate(sector_5_firms):\n",
    "    firm_inputs = supplier_agg['volume'][:, firm_idx]\n",
    "    print(f\"  Firm {firm_idx + 1}: {firm_inputs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Synthetic Shock Generation\n",
    "\n",
    "Now we demonstrate the core contribution of the paper: generating synthetic firm-level shocks that maintain sector-level consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empirical shock: 100% shock to firm 3 (index 2), 0% to all others\n",
    "empirical_shock = np.zeros(n_firms)\n",
    "empirical_shock[2] = 1.0  # Firm 3 gets 100% shock\n",
    "\n",
    "print(f\"Empirical shock vector: {empirical_shock}\")\n",
    "print(f\"Shocked firm: {np.where(empirical_shock > 0)[0] + 1} (sector {sector_affiliations[2]})\")\n",
    "\n",
    "# Initialize shock sampler\n",
    "sampler = ShockSampler(random_seed=100)  # For reproducibility\n",
    "\n",
    "# Generate synthetic shocks\n",
    "synthetic_shocks = sampler.sample_firm_level_shocks(\n",
    "    firm_shock=empirical_shock,\n",
    "    network=W,\n",
    "    sector_affiliations=sector_affiliations,\n",
    "    n_scenarios=10,\n",
    "    sample_mode=\"empirical\",\n",
    "    tracker=False,\n",
    "    silent=True\n",
    ")\n",
    "\n",
    "print(f\"\\nGenerated synthetic shocks: {synthetic_shocks.shape}\")\n",
    "print(f\"Number of scenarios: {synthetic_shocks.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Synthetic Shocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the synthetic shocks\n",
    "print(\"Synthetic shock analysis:\")\n",
    "print(f\"Non-zero elements per scenario: {np.sum(synthetic_shocks > 0, axis=0)}\")\n",
    "\n",
    "# Check which firms get shocked in each scenario\n",
    "for scenario in range(min(5, synthetic_shocks.shape[1])):\n",
    "    shocked_firms = np.where(synthetic_shocks[:, scenario] > 0)[0]\n",
    "    shocked_sectors = sector_affiliations[shocked_firms]\n",
    "    print(f\"Scenario {scenario + 1}: Firms {shocked_firms + 1} in sectors {shocked_sectors}\")\n",
    "\n",
    "# Verify sector-level consistency\n",
    "s_in = np.sum(W, axis=0)   # In-strength\n",
    "s_out = np.sum(W, axis=1)  # Out-strength\n",
    "\n",
    "print(\"\\nSector-level shock consistency check:\")\n",
    "sector_2_mask = sector_affiliations == 2\n",
    "\n",
    "# Original sector 2 shocks\n",
    "orig_in_shock = np.sum(s_in[sector_2_mask] * empirical_shock[sector_2_mask])\n",
    "orig_out_shock = np.sum(s_out[sector_2_mask] * empirical_shock[sector_2_mask])\n",
    "print(f\"Original sector 2 in-shock: {orig_in_shock:.3f}\")\n",
    "print(f\"Original sector 2 out-shock: {orig_out_shock:.3f}\")\n",
    "\n",
    "# Synthetic sector 2 shocks\n",
    "print(\"\\nSynthetic sector 2 shocks:\")\n",
    "for scenario in range(min(5, synthetic_shocks.shape[1])):\n",
    "    synth_shock = synthetic_shocks[:, scenario]\n",
    "    synth_in_shock = np.sum(s_in[sector_2_mask] * synth_shock[sector_2_mask])\n",
    "    synth_out_shock = np.sum(s_out[sector_2_mask] * synth_shock[sector_2_mask])\n",
    "    print(f\"Scenario {scenario + 1}: in={synth_in_shock:.3f}, out={synth_out_shock:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Shock Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize shock distributions\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Heatmap of all synthetic shocks\n",
    "im1 = ax1.imshow(synthetic_shocks, aspect='auto', cmap='Reds')\n",
    "ax1.set_xlabel('Scenario')\n",
    "ax1.set_ylabel('Firm')\n",
    "ax1.set_title('Synthetic Shock Matrix')\n",
    "plt.colorbar(im1, ax=ax1)\n",
    "\n",
    "# 2. Distribution of shock values\n",
    "shock_values = synthetic_shocks[synthetic_shocks > 0]\n",
    "ax2.hist(shock_values, bins=20, alpha=0.7, color='red')\n",
    "ax2.set_xlabel('Shock Intensity')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.set_title('Distribution of Non-Zero Shock Values')\n",
    "\n",
    "# 3. Number of shocked firms per scenario\n",
    "shocked_counts = np.sum(synthetic_shocks > 0, axis=0)\n",
    "ax3.bar(range(1, len(shocked_counts) + 1), shocked_counts, color='blue', alpha=0.7)\n",
    "ax3.set_xlabel('Scenario')\n",
    "ax3.set_ylabel('Number of Shocked Firms')\n",
    "ax3.set_title('Shocked Firms per Scenario')\n",
    "\n",
    "# 4. Sector-level shock consistency\n",
    "sector_in_shocks = []\n",
    "sector_out_shocks = []\n",
    "for scenario in range(synthetic_shocks.shape[1]):\n",
    "    synth_shock = synthetic_shocks[:, scenario]\n",
    "    in_shock = np.sum(s_in[sector_2_mask] * synth_shock[sector_2_mask])\n",
    "    out_shock = np.sum(s_out[sector_2_mask] * synth_shock[sector_2_mask])\n",
    "    sector_in_shocks.append(in_shock)\n",
    "    sector_out_shocks.append(out_shock)\n",
    "\n",
    "scenarios = range(1, len(sector_in_shocks) + 1)\n",
    "ax4.plot(scenarios, sector_in_shocks, 'o-', label='In-strength shock', color='blue')\n",
    "ax4.plot(scenarios, sector_out_shocks, 's-', label='Out-strength shock', color='red')\n",
    "ax4.axhline(orig_in_shock, color='blue', linestyle='--', alpha=0.7, label='Original in-shock')\n",
    "ax4.axhline(orig_out_shock, color='red', linestyle='--', alpha=0.7, label='Original out-shock')\n",
    "ax4.set_xlabel('Scenario')\n",
    "ax4.set_ylabel('Sector-level Shock')\n",
    "ax4.set_title('Sector-level Shock Consistency')\n",
    "ax4.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Economic Impact Analysis\n",
    "\n",
    "Now let's analyze the economic impact using influence vectors based on PageRank, as mentioned in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate influence vectors using PageRank\n",
    "alpha = 0.5  # Labor share (dampening factor)\n",
    "\n",
    "# Firm-level influence vector\n",
    "G_firm = nx.from_numpy_array(W.T, create_using=nx.DiGraph)  # Transpose for out-strength normalization\n",
    "firm_influence = nx.pagerank(G_firm, alpha=1-alpha)\n",
    "firm_influence_vec = np.array([firm_influence[i] for i in range(n_firms)])\n",
    "\n",
    "# Sector-level influence vector  \n",
    "G_sector = nx.from_numpy_array(Z.T, create_using=nx.DiGraph)\n",
    "sector_influence = nx.pagerank(G_sector, alpha=1-alpha)\n",
    "sector_influence_vec = np.array([sector_influence[i] for i in range(len(np.unique(sector_affiliations)))])\n",
    "\n",
    "print(f\"Firm-level influence vector: {firm_influence_vec}\")\n",
    "print(f\"Sector-level influence vector: {sector_influence_vec}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate economy-wide losses\n",
    "firm_level_losses = []\n",
    "for scenario in range(synthetic_shocks.shape[1]):\n",
    "    loss = np.dot(firm_influence_vec, synthetic_shocks[:, scenario])\n",
    "    firm_level_losses.append(loss)\n",
    "\n",
    "# Calculate sector-level equivalent\n",
    "# First, calculate initial sector shocks from firm-level data\n",
    "sector_initial_shocks = np.zeros(len(np.unique(sector_affiliations)))\n",
    "for i, sector in enumerate(np.unique(sector_affiliations)):\n",
    "    sector_mask = sector_affiliations == sector\n",
    "    sector_initial_shocks[i] = np.sum(empirical_shock[sector_mask] * s_out[sector_mask]) / max(np.sum(s_out[sector_mask]), 1e-10)\n",
    "\n",
    "sector_level_loss = np.dot(sector_influence_vec, sector_initial_shocks)\n",
    "\n",
    "print(f\"Economy-wide losses from firm-level analysis: {firm_level_losses}\")\n",
    "print(f\"Economy-wide loss from sector-level analysis: {sector_level_loss}\")\n",
    "print(f\"Mean firm-level loss: {np.mean(firm_level_losses):.6f}\")\n",
    "print(f\"Standard deviation: {np.std(firm_level_losses):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Economic Impact Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization comparing firm-level vs sector-level predictions\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# 1. Distribution of firm-level losses\n",
    "ax1.hist(firm_level_losses, bins=15, alpha=0.7, color='skyblue', \n",
    "         label='Firm-level predictions', density=True)\n",
    "ax1.axvline(sector_level_loss, color='red', linestyle='--', linewidth=2,\n",
    "           label='Sector-level prediction')\n",
    "ax1.axvline(np.mean(firm_level_losses), color='blue', linestyle='-', linewidth=2,\n",
    "           label='Mean firm-level')\n",
    "ax1.set_xlabel('Economy-wide Output Loss')\n",
    "ax1.set_ylabel('Density')\n",
    "ax1.set_title('Economic Impact: Firm-level vs Sector-level Predictions')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Scenario-by-scenario comparison\n",
    "scenarios = range(1, len(firm_level_losses) + 1)\n",
    "ax2.plot(scenarios, firm_level_losses, 'o-', color='blue', \n",
    "         label='Firm-level losses', alpha=0.8)\n",
    "ax2.axhline(sector_level_loss, color='red', linestyle='--', linewidth=2,\n",
    "           label='Sector-level loss')\n",
    "ax2.fill_between(scenarios, \n",
    "                 [sector_level_loss] * len(scenarios),\n",
    "                 firm_level_losses, \n",
    "                 alpha=0.2, color='gray',\n",
    "                 label='Prediction error')\n",
    "ax2.set_xlabel('Scenario')\n",
    "ax2.set_ylabel('Economy-wide Output Loss')\n",
    "ax2.set_title('Loss Predictions by Scenario')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate prediction error statistics\n",
    "prediction_errors = np.array(firm_level_losses) - sector_level_loss\n",
    "print(f\"\\nPrediction Error Analysis:\")\n",
    "print(f\"Mean error: {np.mean(prediction_errors):.6f}\")\n",
    "print(f\"Standard deviation of errors: {np.std(prediction_errors):.6f}\")\n",
    "print(f\"Range of errors: [{np.min(prediction_errors):.6f}, {np.max(prediction_errors):.6f}]\")\n",
    "print(f\"Relative error (% of sector prediction): {100 * np.std(prediction_errors) / abs(sector_level_loss):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sensitivity Analysis\n",
    "\n",
    "Let's explore how the results change with different parameters and network structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitivity analysis: different shock magnitudes\n",
    "shock_magnitudes = [0.25, 0.5, 0.75, 1.0]\n",
    "results_by_magnitude = {}\n",
    "\n",
    "for magnitude in shock_magnitudes:\n",
    "    # Create shock\n",
    "    test_shock = np.zeros(n_firms)\n",
    "    test_shock[2] = magnitude  # Firm 3\n",
    "    \n",
    "    # Generate synthetic shocks\n",
    "    synth_shocks = sampler.sample_firm_level_shocks(\n",
    "        firm_shock=test_shock,\n",
    "        network=W,\n",
    "        sector_affiliations=sector_affiliations,\n",
    "        n_scenarios=20,\n",
    "        silent=True\n",
    "    )\n",
    "    \n",
    "    # Calculate losses\n",
    "    losses = [np.dot(firm_influence_vec, synth_shocks[:, s]) for s in range(synth_shocks.shape[1])]\n",
    "    \n",
    "    results_by_magnitude[magnitude] = {\n",
    "        'losses': losses,\n",
    "        'mean': np.mean(losses),\n",
    "        'std': np.std(losses)\n",
    "    }\n",
    "\n",
    "# Plot sensitivity results\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Mean losses vs shock magnitude\n",
    "magnitudes = list(results_by_magnitude.keys())\n",
    "means = [results_by_magnitude[m]['mean'] for m in magnitudes]\n",
    "stds = [results_by_magnitude[m]['std'] for m in magnitudes]\n",
    "\n",
    "ax1.errorbar(magnitudes, means, yerr=stds, marker='o', capsize=5, capthick=2)\n",
    "ax1.set_xlabel('Shock Magnitude')\n",
    "ax1.set_ylabel('Mean Economy-wide Loss')\n",
    "ax1.set_title('Loss vs Shock Magnitude')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Standard deviation vs shock magnitude\n",
    "ax2.plot(magnitudes, stds, 'o-', color='red')\n",
    "ax2.set_xlabel('Shock Magnitude')\n",
    "ax2.set_ylabel('Standard Deviation of Losses')\n",
    "ax2.set_title('Prediction Uncertainty vs Shock Magnitude')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Sensitivity Analysis Results:\")\n",
    "for magnitude in magnitudes:\n",
    "    result = results_by_magnitude[magnitude]\n",
    "    print(f\"Magnitude {magnitude}: Mean={result['mean']:.6f}, Std={result['std']:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparison with Different Similarity Measures\n",
    "\n",
    "Let's compare different similarity measures to understand their behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different similarity measures\n",
    "similarity_measures = ['jaccard', 'overlap_relative', 'cosine']\n",
    "similarity_results = {}\n",
    "\n",
    "for measure in similarity_measures:\n",
    "    input_sim = similarity_calc.calculate_io_similarities(\n",
    "        W, sector_affiliations, \n",
    "        direction=\"input\", \n",
    "        measure=measure\n",
    "    )\n",
    "    \n",
    "    output_sim = similarity_calc.calculate_io_similarities(\n",
    "        W, sector_affiliations, \n",
    "        direction=\"output\", \n",
    "        measure=measure\n",
    "    )\n",
    "    \n",
    "    similarity_results[measure] = {\n",
    "        'input': input_sim,\n",
    "        'output': output_sim\n",
    "    }\n",
    "\n",
    "# Create comparison table\n",
    "print(\"Similarity Measure Comparison:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for measure in similarity_measures:\n",
    "    print(f\"\\n{measure.upper()}:\")\n",
    "    \n",
    "    input_sim = similarity_results[measure]['input']\n",
    "    output_sim = similarity_results[measure]['output']\n",
    "    \n",
    "    for sector_name in input_sim.keys():\n",
    "        if input_sim[sector_name].size > 1:\n",
    "            in_vals = input_sim[sector_name][np.tril_indices_from(input_sim[sector_name], k=-1)]\n",
    "            out_vals = output_sim[sector_name][np.tril_indices_from(output_sim[sector_name], k=-1)]\n",
    "            \n",
    "            if len(in_vals) > 0:\n",
    "                print(f\"  {sector_name}: Input={in_vals[0]:.3f}, Output={out_vals[0]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusions and Key Insights\n",
    "\n",
    "This notebook has demonstrated the key concepts from the \"Misestimation from Aggregation\" paper:\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Network Aggregation Effects**: When we aggregate firm-level networks to sector-level, we lose important heterogeneity information.\n",
    "\n",
    "2. **Similarity Measures**: Different firms within the same sector can have very different input/output patterns, leading to varying overlap coefficients.\n",
    "\n",
    "3. **Shock Propagation**: The synthetic shock generation algorithm successfully creates heterogeneous firm-level shocks that maintain sector-level consistency.\n",
    "\n",
    "4. **Economic Prediction Errors**: Sector-level analysis can lead to systematic misestimation of economic impacts compared to firm-level analysis.\n",
    "\n",
    "### Practical Implications:\n",
    "\n",
    "- **Policy Making**: Sector-level economic models may underestimate or overestimate the true impact of economic shocks.\n",
    "- **Risk Assessment**: Firm-level heterogeneity creates additional uncertainty that should be considered in economic forecasting.\n",
    "- **Network Analysis**: The methodology provides tools for better understanding production network structure and shock propagation.\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Apply the methodology to larger, real-world production networks\n",
    "- Explore different shock scenarios and network structures\n",
    "- Investigate the relationship between network topology and prediction accuracy\n",
    "- Develop improved aggregation methods that preserve more firm-level information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Network size: {n_firms} firms, {len(np.unique(sector_affiliations))} sectors\")\n",
    "print(f\"Network density: {np.sum(W > 0) / (n_firms * n_firms):.3f}\")\n",
    "print(f\"Total network flow: {np.sum(W)}\")\n",
    "print(f\"\")\n",
    "print(f\"Synthetic shocks generated: {synthetic_shocks.shape[1]} scenarios\")\n",
    "print(f\"Average shocked firms per scenario: {np.mean(np.sum(synthetic_shocks > 0, axis=0)):.1f}\")\n",
    "print(f\"\")\n",
    "print(f\"Economy-wide loss predictions:\")\n",
    "print(f\"  Firm-level mean: {np.mean(firm_level_losses):.6f}\")\n",
    "print(f\"  Firm-level std:  {np.std(firm_level_losses):.6f}\")\n",
    "print(f\"  Sector-level:    {sector_level_loss:.6f}\")\n",
    "print(f\"  Prediction error: {100 * abs(np.mean(firm_level_losses) - sector_level_loss) / abs(sector_level_loss):.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}